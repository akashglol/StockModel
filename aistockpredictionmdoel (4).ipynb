{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChhrGIK5rH9W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd68632b-2b31-418d-b600-1bd963034b9b",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r[*********************100%%**********************]  1 of 1 completed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Download stock data\n",
        "stock_data = yf.download('NVDA', start='2023-01-01', end='2024-07-01')\n",
        "\n",
        "# Create additional features\n",
        "stock_data['MA_20'] = stock_data['Close'].rolling(window=20).mean()  # 20-day moving average\n",
        "stock_data['MA_50'] = stock_data['Close'].rolling(window=50).mean()  # 50-day moving average\n",
        "\n",
        "# Drop NaN values created by moving averages\n",
        "stock_data.dropna(inplace=True)\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(stock_data[['Close', 'Open', 'High', 'Low', 'Volume', 'MA_20', 'MA_50']].values)\n",
        "\n",
        "# Create dataset\n",
        "def create_dataset(data, time_step):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step)])\n",
        "        y.append(data[i + time_step, 0])  # Predicting 'Close' price\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "time_step = 60\n",
        "X, y = create_dataset(scaled_data, time_step)\n",
        "\n",
        "# Check if the dataset is empty\n",
        "if X.size == 0 or y.size == 0:\n",
        "    raise ValueError(\"Not enough data to create the dataset with the given time_step. Please use a smaller time_step.\")\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_train, y_test = y[:train_size], y[train_size:]\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64, return_sequences=True, input_shape=(time_step, X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=64))\n",
        "model.add(Dense(units=1))\n",
        "\n",
        "# Compile and fit the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')\n",
        "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss = model.evaluate(X_test, y_test)\n",
        "print('Test Loss:', test_loss)\n",
        "\n",
        "# Predict the test data\n",
        "predictions = model.predict(X_test)\n",
        "predictions = scaler.inverse_transform(np.concatenate((predictions, np.zeros((predictions.shape[0], 6))), axis=1))[:, 0]\n",
        "\n",
        "# Plot the original and predicted data\n",
        "original_data = stock_data['Close'].values\n",
        "predicted_data = np.empty_like(original_data)\n",
        "predicted_data[:] = np.nan\n",
        "predicted_data[-len(predictions):] = predictions\n",
        "\n",
        "plt.plot(original_data, label='Original Data')\n",
        "plt.plot(predicted_data, label='Predicted Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Predict the next week's stock prices\n",
        "X_input = scaled_data[-time_step:].reshape(1, time_step, X.shape[2])\n",
        "predictions = []\n",
        "\n",
        "for _ in range(7):\n",
        "    next_prediction = model.predict(X_input)\n",
        "    predictions.append(next_prediction[0, 0])\n",
        "    next_input = np.concatenate((next_prediction, np.zeros((1, 6))), axis=1)\n",
        "    X_input = np.append(X_input[:, 1:, :], next_input.reshape(1, 1, X.shape[2]), axis=1)\n",
        "\n",
        "predicted_prices = scaler.inverse_transform(np.concatenate((np.array(predictions).reshape(-1, 1), np.zeros((len(predictions), 6))), axis=1))[:, 0]\n",
        "\n",
        "# Generate dates for the next week\n",
        "last_date = stock_data.index[-1]\n",
        "dates = [last_date + timedelta(days=i) for i in range(1, 8)]\n",
        "\n",
        "# Plotting the predictions\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(dates, predicted_prices, marker='o', linestyle='-', color='orange', label='Predicted Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.title('Predicted Stock Prices for the Next Week')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the predicted opening and closing prices for each day\n",
        "print(\"Predicted Opening and Closing Prices for the Next Week:\")\n",
        "for i, date in enumerate(dates):\n",
        "    print(f\"{date.date()}: Open: {predicted_prices[i]:.2f}, Close: {predicted_prices[i]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OPUJlKKxtHL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}