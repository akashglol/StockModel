{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChhrGIK5rH9W",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Dropout\n",
        "from datetime import datetime, timedelta\n",
        "import pandas_datareader as pdr\n",
        "\n",
        "# Download stock data\n",
        "stock_data = yf.download('NVDA', start='2023-01-01', end='2024-07-01')\n",
        "\n",
        "# Add earnings reports data\n",
        "nvda = yf.Ticker('NVDA')\n",
        "earnings = nvda.earnings_dates\n",
        "earnings.reset_index(inplace=True)\n",
        "earnings = earnings.rename(columns={\"index\": \"Date\"})\n",
        "earnings['Date'] = pd.to_datetime(earnings['Date'])\n",
        "stock_data = stock_data.merge(earnings[['Date']], how='left', on='Date')\n",
        "stock_data['Earnings'] = stock_data['Date'].notna().astype(int)\n",
        "\n",
        "# Add economic indicators data: GDP\n",
        "gdp_data = pdr.get_data_fred('GDP', start=datetime(2023, 1, 1), end=datetime(2024, 7, 1))\n",
        "gdp_data = gdp_data.rename(columns={\"GDP\": \"GDP_Quarterly\"})\n",
        "gdp_data = gdp_data.resample('D').ffill().reset_index()  # Fill daily with forward fill\n",
        "stock_data = stock_data.reset_index().merge(gdp_data, how='left', on='Date').set_index('Date')\n",
        "\n",
        "# Create additional features\n",
        "stock_data['MA_20'] = stock_data['Close'].rolling(window=20).mean()  # 20-day moving average\n",
        "stock_data['MA_50'] = stock_data['Close'].rolling(window=50).mean()  # 50-day moving average\n",
        "\n",
        "# Create a binary target variable for price increase\n",
        "stock_data['Price_Increase'] = (stock_data['Close'].shift(-1) > stock_data['Close']).astype(int)\n",
        "stock_data.dropna(inplace=True)  # Drop NaN values created by moving averages\n",
        "\n",
        "# Scale the data\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "scaled_data = scaler.fit_transform(stock_data[['Close', 'Open', 'High', 'Low', 'Volume', 'MA_20', 'MA_50', 'Earnings', 'GDP_Quarterly']].values)\n",
        "\n",
        "# Create dataset\n",
        "def create_dataset(data, time_step):\n",
        "    X, y_price, y_increase = [], [], []\n",
        "    for i in range(len(data) - time_step - 1):\n",
        "        X.append(data[i:(i + time_step)])\n",
        "        y_price.append(data[i + time_step, 0])  # Predicting 'Close' price\n",
        "        y_increase.append(data[i + time_step, -1])  # Predicting 'Price_Increase'\n",
        "    return np.array(X), np.array(y_price), np.array(y_increase)\n",
        "\n",
        "time_step = 60\n",
        "X, y_price, y_increase = create_dataset(scaled_data, time_step)\n",
        "\n",
        "# Check if the dataset is empty\n",
        "if X.size == 0 or y_price.size == 0 or y_increase.size == 0:\n",
        "    raise ValueError(\"Not enough data to create the dataset with the given time_step. Please use a smaller time_step.\")\n",
        "\n",
        "# Split data into train and test sets\n",
        "train_size = int(len(X) * 0.8)\n",
        "X_train, X_test = X[:train_size], X[train_size:]\n",
        "y_price_train, y_price_test = y_price[:train_size], y_price[train_size:]\n",
        "y_increase_train, y_increase_test = y_increase[:train_size], y_increase[train_size:]\n",
        "\n",
        "# Build the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(units=64, return_sequences=True, input_shape=(time_step, X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(units=64))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(units=64))\n",
        "model.add(Dense(units=2))  # Two outputs: price and increase/decrease\n",
        "\n",
        "# Compile and fit the model\n",
        "model.compile(optimizer='adam', loss=['mean_squared_error', 'binary_crossentropy'], metrics=['accuracy'])\n",
        "model.fit(X_train, [y_price_train, y_increase_train], epochs=50, batch_size=64, validation_data=(X_test, [y_price_test, y_increase_test]))\n",
        "\n",
        "# Evaluate the model\n",
        "test_loss, test_acc = model.evaluate(X_test, [y_price_test, y_increase_test])\n",
        "print('Test Loss:', test_loss)\n",
        "print('Test Accuracy:', test_acc)\n",
        "\n",
        "# Predict the test data\n",
        "predictions_price, predictions_increase = model.predict(X_test)\n",
        "predictions_price = scaler.inverse_transform(np.concatenate((predictions_price, np.zeros((predictions_price.shape[0], 8))), axis=1))[:, 0]\n",
        "predictions_increase = (predictions_increase > 0.5).astype(int)\n",
        "\n",
        "# Plot the original and predicted data\n",
        "original_data = stock_data['Close'].values\n",
        "predicted_data = np.empty_like(original_data)\n",
        "predicted_data[:] = np.nan\n",
        "predicted_data[-len(predictions_price):] = predictions_price\n",
        "\n",
        "plt.plot(original_data, label='Original Data')\n",
        "plt.plot(predicted_data, label='Predicted Data')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# Predict the next week's stock prices\n",
        "X_input = scaled_data[-time_step:].reshape(1, time_step, X.shape[2])\n",
        "predictions = []\n",
        "\n",
        "for _ in range(7):\n",
        "    next_prediction_price, next_prediction_increase = model.predict(X_input)\n",
        "    predictions.append(next_prediction_price[0, 0])\n",
        "    next_input = np.concatenate((next_prediction_price, np.zeros((1, 8))), axis=1)\n",
        "    X_input = np.append(X_input[:, 1:, :], next_input.reshape(1, 1, X.shape[2]), axis=1)\n",
        "\n",
        "predicted_prices = scaler.inverse_transform(np.concatenate((np.array(predictions).reshape(-1, 1), np.zeros((len(predictions), 8))), axis=1))[:, 0]\n",
        "\n",
        "# Generate dates for the next week\n",
        "last_date = stock_data.index[-1]\n",
        "dates = [last_date + timedelta(days=i) for i in range(1, 8)]\n",
        "\n",
        "# Plotting the predictions\n",
        "plt.figure(figsize=(14, 7))\n",
        "plt.plot(dates, predicted_prices, marker='o', linestyle='-', color='orange', label='Predicted Data')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Stock Price')\n",
        "plt.title('Predicted Stock Prices for the Next Week')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "# Print the predicted opening and closing prices for each day\n",
        "print(\"Predicted Opening and Closing Prices for the Next Week:\")\n",
        "for i, date in enumerate(dates):\n",
        "    print(f\"{date.date()}: Open: {predicted_prices[i]:.2f}, Close: {predicted_prices[i]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "7OPUJlKKxtHL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}